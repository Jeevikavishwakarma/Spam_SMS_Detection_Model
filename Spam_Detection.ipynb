{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwqhMPVQabPn9o3OcI5IVR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeevikavishwakarma/Spam_SMS_Detection_Model/blob/main/Spam_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibg3Rd2AL5-8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dataset = pd.read_csv('spam.csv', encoding = 'latin-1')\n",
        "df = dataset.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2yHU1p7NFMD",
        "outputId": "b4284666-672e-47f3-b93f-f866e67aedf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['v1','v2']]\n",
        "df.columns = ['label', 'message']\n",
        "print(df.head())\n",
        "print(df.label.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leuQbCOlNRqM",
        "outputId": "d1d76eb2-95c7-4ad9-aaef-8e9ac97257d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                            message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def clean_text(msg):\n",
        "  msg = msg.lower()\n",
        "  msg = re.sub(r'[^a-z\\s]','', msg)\n",
        "  tokens = msg.split()\n",
        "  tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "df['cleaned'] = df['message'].apply(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlC-56PlNg6_",
        "outputId": "24af3ac9-37f6-40d0-d246-66b68aeb4dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].map({'ham':0,'spam':1})"
      ],
      "metadata": {
        "id": "P59PEb--OXpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vector = TfidfVectorizer(max_features =3000)\n",
        "X = vector.fit_transform(df['cleaned']).toarray()\n",
        "y = df['label']\n"
      ],
      "metadata": {
        "id": "SVCkOebcOgps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size =0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "HfZ56AruO1T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "model =  MultinomialNB()\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "hioX4C2hPC_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \", accuracy_score(y_test,y_pred))\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Nj1WLxfPfMp",
        "outputId": "bcf51e6d-8120-4415-ad2c-e6862c3fe437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9766816143497757\n",
            "[[965   0]\n",
            " [ 26 124]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       965\n",
            "           1       1.00      0.83      0.91       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.99      0.91      0.95      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}